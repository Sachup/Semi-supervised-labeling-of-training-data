{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd35095",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is inspired from the tutorial of Nicholas Renotte -Siamese neural network-Tutorial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1f7b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os                \n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86394da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer,Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bcc76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\sachu\\Desktop\\My_Documents\\Research_Project\\Computer_Graphics\\CAR_TEST\\Siamese_Model\\50_input_set\"#Path to 50 image input training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d935f2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gpus= tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa54c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to various folders containing negative, positive,and anchor images\n",
    "POS_PATH = os.path.join(path,'positive')\n",
    "NEG_PATH = os.path.join(path,'negative')\n",
    "ANC_PATH = os.path.join(path,'anchor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd8609",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for Data augmentation\n",
    "def data_aug(img):\n",
    "    data = []\n",
    "    for i in range(9):\n",
    "        img = tf.image.stateless_random_brightness(img, max_delta=0.02, seed=(1,2))\n",
    "        img = tf.image.stateless_random_contrast(img, lower=0.6, upper=1, seed=(1,3))\n",
    "        # img = tf.image.stateless_random_crop(img, size=(20,20,3), seed=(1,2))\n",
    "        img = tf.image.stateless_random_flip_left_right(img, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "        img = tf.image.stateless_random_jpeg_quality(img, min_jpeg_quality=90, max_jpeg_quality=100, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "        img = tf.image.stateless_random_saturation(img, lower=0.9,upper=1, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "            \n",
    "        data.append(img)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afc6bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for file_name in os.listdir(os.path.join(NEG_PATH)):\n",
    "    img_path = os.path.join(NEG_PATH, file_name)\n",
    "    img = cv2.imread(img_path)\n",
    "    augmented_images = data_aug(img) \n",
    "    \n",
    "    for image in augmented_images:\n",
    "        cv2.imwrite(os.path.join(NEG_PATH, '{}.jpg'.format(uuid.uuid1())), image.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afeb149",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = tf.data.Dataset.list_files(ANC_PATH+'\\*.jpg').take(500)\n",
    "positive = tf.data.Dataset.list_files(POS_PATH+'\\*.jpg').take(500)\n",
    "negative = tf.data.Dataset.list_files(NEG_PATH+'\\*.jpg').take(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66e2bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_path): \n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    img = tf.image.resize(img, (100,100)) \n",
    "    img = img / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d522ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "positives=tf.data.Dataset.zip((anchor,positive,tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives=tf.data.Dataset.zip((anchor,negative,tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "data=positives.concatenate(negatives)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d0aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_twin(input_img, validation_img,label):\n",
    "    return(preprocess(input_img),preprocess(validation_img),label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d375fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.map(preprocess_twin)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c3c343",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.take(round(len(data)*.7))\n",
    "train_data = train_data.batch(16)\n",
    "train_data =train_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65606f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data.skip(round(len(data)*.7))\n",
    "test_data = test_data.take(round(len(data)*.3))\n",
    "test_data=test_data.batch(16)\n",
    "test_data=test_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530b7e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding():\n",
    "    inp = Input(shape=(100,100,3), name='input_image')\n",
    "    c1= Conv2D(64, (10,10),activation='relu')(inp)            \n",
    "    m1 = MaxPooling2D(64, (2,2), padding='same')(c1)          \n",
    "    c2= Conv2D(128, (7,7),activation='relu')(m1)\n",
    "    m2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n",
    "    c3= Conv2D(128, (4,4),activation='relu')(m2)\n",
    "    m3 = MaxPooling2D(64, (2,2), padding='same')(c3)\n",
    "    c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
    "    f1 = Flatten()(c4)\n",
    "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
    "    return Model(inputs=[inp], outputs=[d1], name='embedding')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a960a0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding=make_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5beb1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fc9335",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1Dist(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super().__init__()\n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf2cfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Input(name='input_img', shape=(100,100,3))\n",
    "validation_image = Input(name='validation_img', shape=(100,100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd9e5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_embedding = embedding(input_image)\n",
    "val_embedding = embedding(validation_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02e92d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_layer = L1Dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128d5d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_layer(inp_embedding, val_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d834307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_model():\n",
    "    input_image = Input(name='input_img', shape=(100,100,3))\n",
    "    validation_image = Input(name='validation_img', shape=(100,100,3))\n",
    "    siamese_layer = L1Dist()\n",
    "    siamese_layer._name = 'distance'\n",
    "    distances = siamese_layer(embedding(input_image), embedding(validation_image))\n",
    "    classifier = Dense(1,activation='sigmoid')(distances)\n",
    "    return Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae2fd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = make_siamese_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7dcdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015213f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_loss = tf.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930f3371",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=tf.keras.optimizers.Adam(1e-03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7fdb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir,'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e723ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function   \n",
    "def train_step(batch):   \n",
    "    with tf.GradientTape() as tape:     \n",
    "        X = batch[:2]\n",
    "        y=batch[2]\n",
    "        yhat = siamese_model(X, training=True)  \n",
    "        loss = binary_cross_loss(y, yhat)\n",
    "    print(loss)\n",
    "    grad = tape.gradient(loss, siamese_model.trainable_variables)           \n",
    "    opt.apply_gradients(zip(grad, siamese_model.trainable_variables))    \n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a24ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d739464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, EPOCHS):\n",
    "    losses=[]\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        print('\\n Epoch{}/{}'.format(epoch, EPOCHS))\n",
    "        progbar = tf.keras.utils.Progbar(len(data))\n",
    "        r = Recall()\n",
    "        p = Precision()\n",
    "        \n",
    "        for idx, batch in enumerate(data):\n",
    "            loss = train_step(batch)\n",
    "            yhat = siamese_model.predict(batch[:2])\n",
    "            r.update_state(batch[2], yhat)\n",
    "            p.update_state(batch[2], yhat)\n",
    "            progbar.update(idx+1)\n",
    "        print(loss.numpy(), r.result().numpy(), p.result().numpy())\n",
    "        losses.append(loss.numpy())\n",
    "        if epoch % 10 ==0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "            \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3f0c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80379246",
   "metadata": {},
   "outputs": [],
   "source": [
    "lops=train(train_data,EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5e166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "epo = np.arange(1,121)\n",
    "plt.plot(epo,lops)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5e01b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "siamese_model.save('siamesemodel_CARTEST_50_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c688cbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('siamesemodel_CARTEST_50_2.h5', custom_objects = {'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy},compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d483a054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d468aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'C:\\\\Users\\\\sachu\\\\Desktop\\\\My_Documents\\\\Research_Project\\\\Computer_Graphics\\\\Siamese Attempt_on_Kitti_dataset\\\\data\\\\positive'\n",
    "dest = 'C:\\\\Users\\\\sachu\\\\Desktop\\\\My_Documents\\\\Research_Project\\\\Computer_Graphics\\\\Siamese Attempt_on_Kitti_dataset\\\\application_data\\\\verification_images'\n",
    "files = os.listdir(source)\n",
    "no_of_files = len(files) // 10\n",
    "\n",
    "for file_name in random.sample(files, no_of_files):\n",
    "    shutil.copy(os.path.join(source, file_name), dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36e4329",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(model, detection_threshold, verification_threshold):\n",
    "    ver = []\n",
    "    y = []\n",
    "    z =[]\n",
    "    for img  in os.listdir(os.path.join('application_data','input_images')):\n",
    "        results = []\n",
    "        print(img)\n",
    "        z.append(img)\n",
    "      \n",
    "        for image in os.listdir(os.path.join('application_data','verification_images')):\n",
    "            input_img = preprocess(os.path.join('application_data','input_images',img))\n",
    "            validation_img = preprocess(os.path.join('application_data','verification_images',image))\n",
    "            result = model.predict(list(np.expand_dims([input_img, validation_img],axis=1)))\n",
    "            results.append(result)   \n",
    "        detection = np.sum(np.array(results) > detection_threshold)\n",
    "        verification = detection /len(os.listdir(os.path.join('application_data','verification_images')))\n",
    "        verified  = verification > verification_threshold\n",
    "        ver.append(verified)\n",
    "        print(results)\n",
    "        print(verified)\n",
    "    print (ver)\n",
    "    return ver,z\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004ec273",
   "metadata": {},
   "outputs": [],
   "source": [
    "veri,zi = verify(model,0.9, 0.5)#Alter these 2 detection threshold and verification threshold to find the optimal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60652283",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(veri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a766f794",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4a158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    if veri[i] == True:\n",
    "        print(zi[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f8b1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    if veri[i] == False:\n",
    "        print(zi[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eebe4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [['img1.jpg',False],['img2.jpg',False],['img3.jpg',False],['img4.jpg',False],['img5.jpg',False],['img6.jpg',False],['img7.jpg',False],['img8.jpg',False],['img9.jpg',False],['img10.jpg',False],['img11.jpg',False],['img12.jpg',False],['img13.jpg',False],['img14.jpg',False],['img15.jpg',False],['img16.jpg',False],['img17.jpg',False],['img18.jpg',False],['img19.jpg',False],['img20.jpg',False],['img21.jpg',False],['img22.jpg',False],['img23.jpg',False],['img24.jpg',False],['img25.jpg',False],['img26.jpg',False],['img27.jpg',False],['img28.jpg',False],['img29.jpg',False],['img30.jpg',False],['img31.jpg',False],['img32.jpg',False],['img33.jpg',False],['img34.jpg',False],['img35.jpg',False],['img36.jpg',False],['img37.jpg',False],['img38.jpg',False],['img39.jpg',False],['img40.jpg',False],['img41.jpg',False],['img42.jpg',False],['img43.jpg',False],['img44.jpg',False],['img45.jpg',False],['img46.jpg',False],['img47.jpg',False],['img48.jpg',False],['img49.jpg',False],['img50.jpg',False],['img51.jpg',False],['img52.jpg',False],['img53.jpg',False],['img54.jpg',False],['img55.jpg',False],['img56.jpg',False],['img57.jpg',False],['img58.jpg',False],['img59.jpg',False],['img60.jpg',True],['img61.jpg',True],['img62.jpg',True],['img63.jpg',True],['img64.jpg',True],['img65.jpg',True],['img66.jpg',True],['img67.jpg',True],['img68.jpg',True],['img69.jpg',True],['img70.jpg',True],['img71.jpg',True],['img72.jpg',True],['img73.jpg',True],['img74.jpg',True],['img75.jpg',True],['img76.jpg',True],['img77.jpg',True],['img78.jpg',True],['img79.jpg',True],['img80.jpg',True],['img81.jpg',True],['img82.jpg',True],['img83.jpg',True],['img84.jpg',True],['img85.jpg',True],['img86.jpg',True],['img87.jpg',True],['img88.jpg',True],['img89.jpg',True],['img90.jpg',True],['img91.jpg',True],['img92.jpg',True],['img93.jpg',True],['img94.jpg',True],['img95.jpg',True],['img96.jpg',True],['img97.jpg',True],['img98.jpg',True],['img99.jpg',True],['img100.jpg',True]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099b9f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 0\n",
    "for l in range(100):\n",
    "    for i in a:\n",
    "        if (i[0] == zi[l] and i[1] == veri[l]):\n",
    "            m= m+1\n",
    "print(m)\n",
    "accuracy = m/100\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
